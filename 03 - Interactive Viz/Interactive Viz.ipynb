{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "folium.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Approved Amount    4262\n",
       "Canton             2722\n",
       "Institution        4161\n",
       "University         2903\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the P3 grant data\n",
    "\n",
    "swiss_grant = r'P3_GrantExport.csv'\n",
    "grant_data = pd.read_csv(swiss_grant,  sep=';', header=0, index_col=0, usecols=[0,6,7,13])\n",
    "\n",
    "#Parsing a little the geographical data we have to allow for a simpler processing. Keep the rows where the canton is clearly indicated\n",
    "#in the University column in the original dataframe, moving the others to a new dataframe _missing\n",
    "grant_data_missing = grant_data[grant_data.University.isnull() | grant_data.University.isin([\"Nicht zuteilbar - NA\"])]\n",
    "grant_data = grant_data.drop(grant_data_missing.index)\n",
    "\n",
    "#dropping the rows for which we won't be able to extract the canton of funding\n",
    "grant_data_missing = grant_data_missing[((grant_data_missing.University.isin([\"Nicht zuteilbar - NA\"]) | grant_data_missing.University.isnull() )& grant_data_missing.Institution.isnull()  ) == False]\n",
    "#dropping rows where grant amount is not specified, since it cannot enrich our analysis\n",
    "grant_data_missing.drop(grant_data_missing.ix[grant_data_missing['Approved Amount'] == \"data not included in P3\"].index, inplace= True)\n",
    "\n",
    "grant_data['Canton']= grant_data[\"University\"].str.split(\"- \").str[1]\n",
    "\n",
    "\n",
    "print(grant_data.Institution.unique().size)\n",
    "#We have a total of 5211 Institutions registered in the data. We aim for 95% geolocalisation, that is we shouldn't have more than 261 unparsed ones.\n",
    "\n",
    "grant_data.loc[grant_data.Canton.isin(['LA', 'EPFL', 'HEPL', 'EHB', 'FORS', 'IST', 'SIB' ]), 'Canton'] = 'VD'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHBern', 'RWS', 'BFH']), 'Canton'] = 'BE'\n",
    "grant_data.loc[grant_data.Canton.isin(['ETHZ', 'PHZFH', 'SIK-ISEA', 'EAWAG', 'EMPA', 'FHKD', 'HfH', 'ZFH']), 'Canton'] = 'ZH'\n",
    "grant_data.loc[grant_data.Canton.isin(['IHEID']), 'Canton'] = 'GE'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHGR', 'PMOD', 'AORI', \"und Asthmaforschung \", 'IKG']), 'Canton'] = 'GR'\n",
    "grant_data.loc[grant_data.Canton.isin(['SUPSI', 'IRSOL', 'FUS', 'EOC', 'USI']), 'Canton'] = 'TI'\n",
    "grant_data.loc[grant_data.Canton.isin(['PSI', 'PHFHNW', 'FIBL','FHNW']), 'Canton'] = 'AG'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHSG', 'SHLR', 'KSPSG', 'FHO']), 'Canton'] = 'SG'\n",
    "grant_data.loc[grant_data.Canton.isin(['CSEM', 'ISSKA']), 'Canton'] = 'NE'\n",
    "grant_data.loc[grant_data.Canton.isin(['HEPFR']), 'Canton'] = 'FR'\n",
    "grant_data.loc[grant_data.Canton.isin(['FFHS', 'PHVS', 'CREALP', 'IDIAP', 'IUKB', 'IRO']), 'Canton'] = 'VS'\n",
    "grant_data.loc[grant_data.Canton.isin(['STHB', 'FMI']), 'Canton'] = 'BS'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHSH']), 'Canton'] = 'SH'\n",
    "grant_data.loc[grant_data.Canton.isin(['SPF', 'PHLU', 'HSLU']), 'Canton'] = 'LU'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHZG']), 'Canton'] = 'ZG'\n",
    "grant_data.loc[grant_data.Canton.isin(['BITG', 'PHTG']), 'Canton'] = 'TG'\n",
    "grant_data.loc[grant_data.Canton.isin(['PHSZ']), 'Canton'] = 'SZ'\n",
    "grant_data.loc[grant_data.Canton.isin(['HEPBEJUNE']), 'Canton'] = 'JU'\n",
    "\n",
    "grant_data_refine =grant_data[grant_data.Canton.isin(['NPO', 'HES-SO','ASPIT','FINST','WSL','FP','FTL','IST','ASP', 'AGS'])]\n",
    "grant_data.drop(grant_data.ix[grant_data.Canton.isin(['NPO','HES-SO','ASPIT','FINST','WSL','FP','FTL','ASP', 'AGS'])].index, inplace= True)\n",
    "#NPO, HES-SO, ASPIT, FINST,WSL, FP, FTL, ASP, AGS need further parsing\n",
    "#ISO in Roma -> delete\n",
    "\n",
    "grant_data_refine = pd.concat([grant_data_refine,grant_data_missing])\n",
    "grant_data_refine.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, these are the 4342 rows we have left to parse, approximately 10% of the initial data. We aim for 95% parsed institutions.\n",
    "\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Genève') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Geneva') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('travail social', case=0) == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('HEAD') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Droz') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('CERN') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Martin Bodmer') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains(\"Muséum d'Histoire Naturelle\") == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('genevoise') == True, 'Canton'] = 'GE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Basel') == True, 'Canton'] = 'BS'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Valais') == True, 'Canton'] = 'VS'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('CREPA') == True, 'Canton'] = 'VS'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Sion') == True, 'Canton'] = 'VS'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Fribourg') == True, 'Canton'] = 'FR'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains(\"Ecole d'ingénieurs et d'architectes\") == True, 'Canton'] = 'FR'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains(\"Forschungskomitee Rechtssoziologie\") == True, 'Canton'] = 'FR'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('fribourgeoise') == True, 'Canton'] = 'FR'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Zür') == True, 'Canton'] = 'ZH'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Eawag') == True, 'Canton'] = 'ZH'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('ART') == True, 'Canton'] = 'ZH'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Winterthur') == True, 'Canton'] = 'ZH'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('ETH') == True, 'Canton'] = 'ZH'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Arc', case=0) == True, 'Canton'] = 'JU'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Schaffhausen', case=0) == True, 'Canton'] = 'SH'\n",
    "\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Bibliothèque cantonale jurassienne', case=0) == True, 'Canton'] = 'JU'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Lausanne') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Bibliothèque cantonale') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Vaud', case=0) == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('EPFL') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('EPF-L') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Gonin') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Suisse Occidental') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Lullier') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('La Source') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Changins') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains(\"Ecole d'études sociales et pédagogiques\") == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('HECV') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Heig-VD', case=0) == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('CHUV') == True, 'Canton'] = 'VD'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Bern') == True, 'Canton'] = 'BE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Schweizerische Musikforschende Gesellschaft') == True, 'Canton'] = 'BE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Neuchâtel') == True, 'Canton'] = 'NE'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Scherrer') == True, 'Canton'] = 'AG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Hürlimann') == True, 'Canton'] = 'AG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Baden') == True, 'Canton'] = 'AG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Aar') == True, 'Canton'] = 'AG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('cantonale', case=0) == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Ticin', case=0) == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Lugano') == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Liceo') == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Svizzera') == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Sezione') == True, 'Canton'] = 'TI'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Luzern') == True, 'Canton'] = 'LU'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Thurgau') == True, 'Canton'] = 'TG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('SLF') == True, 'Canton'] = 'GR'  \n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Rumants') == True, 'Canton'] = 'GR' \n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Schwyz') == True, 'Canton'] = 'SZ'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('St. Gall') == True, 'Canton'] = 'SG'\n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('St.Gall') == True, 'Canton'] = 'SG' \n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Zug') == True, 'Canton'] = 'ZG' \n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Solothurn') == True, 'Canton'] = 'SO' \n",
    "grant_data_refine.loc[grant_data_refine.Institution.str.contains('Appenzell') == True, 'Canton'] = 'AR' \n",
    "\n",
    "grant_data_refined = grant_data_refine[grant_data_refine.Canton.isin(['GE','SZ','SO','AG', 'TI', 'ZG', 'GR','SG', 'BS','VS', 'LU', 'FR','ZH', 'LA', 'BE', 'NE', 'AR', 'JU', 'TG'])]\n",
    "grant_data_refine.drop(grant_data_refine.ix[grant_data_refine.Canton.isin(['ZG','SZ','SO','AG', 'TI', 'GE','GR','SG', 'BS','LU', 'TG', 'VS','FR','ZH', 'LA', 'BE', 'NE', 'AR', 'JU'])].index, inplace= True)\n",
    "\n",
    "#grant_data_refine.loc[grant_data_refine.University.isnull()].Institution.unique().size / grant_data_refine.loc[grant_data_refine.University.isnull()].Institution.size\n",
    "#We have 95% of unique Insitution in the list, most of them out of Switzerland, so it is safe to ditch everything left here.\n",
    "grant_data_refine.drop(grant_data_refine.ix[grant_data_refine.University.isnull()].index, inplace= True)\n",
    "\n",
    "\n",
    "#pursuing the parsing...\n",
    "grant_data_refine.drop(grant_data_refine.loc[grant_data_refine.Institution.str.contains('Institute', case=0) == True].index, inplace= True)\n",
    "grant_data_refine.drop(grant_data_refine.loc[grant_data_refine.Institution.str.contains('Department', case=0) == True].index, inplace= True)\n",
    "grant_data_refine.drop(grant_data_refine.loc[grant_data_refine.Institution.str.contains('University', case=0) == True].index, inplace= True)\n",
    "grant_data_refine.drop(grant_data_refine.loc[grant_data_refine.Institution.str.contains('Universität', case=0) == True].index, inplace= True)\n",
    "grant_data_refine.drop(grant_data_refine.loc[grant_data_refine.Institution.str.contains('UNI', case=0) == True].index, inplace= True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#What we use to identify the non parsed institutions\n",
    "#grant_data_refine.sort_values('Approved Amount', ascending=False).Institution.unique()\n",
    "#grant_data_refine.Institution.size\n",
    "\n",
    "grant_data = pd.concat([grant_data,grant_data_refined])\n",
    "grant_data.dropna(subset=['Canton'],inplace=True)\n",
    "grant_data.drop(grant_data.ix[grant_data.Canton.isin(['NPO','HES-SO','ASPIT','FINST','WSL','FP','FTL','ASP', 'AGS', 'ISR'])].index, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approved Amount</th>\n",
       "      <th>cantons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canton</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZH</th>\n",
       "      <td>3.695114e+09</td>\n",
       "      <td>ZH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VD</th>\n",
       "      <td>2.415326e+09</td>\n",
       "      <td>VD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>1.901525e+09</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>1.581336e+09</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS</th>\n",
       "      <td>1.398939e+09</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>4.614244e+08</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>4.050351e+08</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>1.798424e+08</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TI</th>\n",
       "      <td>1.247166e+08</td>\n",
       "      <td>TI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG</th>\n",
       "      <td>9.410458e+07</td>\n",
       "      <td>SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>5.841719e+07</td>\n",
       "      <td>GR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>5.652523e+07</td>\n",
       "      <td>LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JU</th>\n",
       "      <td>5.231398e+07</td>\n",
       "      <td>JU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VS</th>\n",
       "      <td>3.689529e+07</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TG</th>\n",
       "      <td>8.990356e+06</td>\n",
       "      <td>TG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZ</th>\n",
       "      <td>1.483911e+06</td>\n",
       "      <td>SZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1.354401e+06</td>\n",
       "      <td>SO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZG</th>\n",
       "      <td>8.689150e+05</td>\n",
       "      <td>ZG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH</th>\n",
       "      <td>1.766910e+05</td>\n",
       "      <td>SH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1.400000e+05</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>UR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NW</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OW</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>OW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>GL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BL</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Approved Amount cantons\n",
       "Canton                         \n",
       "ZH         3.695114e+09      ZH\n",
       "VD         2.415326e+09      VD\n",
       "GE         1.901525e+09      GE\n",
       "BE         1.581336e+09      BE\n",
       "BS         1.398939e+09      BS\n",
       "FR         4.614244e+08      FR\n",
       "NE         4.050351e+08      NE\n",
       "AG         1.798424e+08      AG\n",
       "TI         1.247166e+08      TI\n",
       "SG         9.410458e+07      SG\n",
       "GR         5.841719e+07      GR\n",
       "LU         5.652523e+07      LU\n",
       "JU         5.231398e+07      JU\n",
       "VS         3.689529e+07      VS\n",
       "TG         8.990356e+06      TG\n",
       "SZ         1.483911e+06      SZ\n",
       "SO         1.354401e+06      SO\n",
       "ZG         8.689150e+05      ZG\n",
       "SH         1.766910e+05      SH\n",
       "AR         1.400000e+05      AR\n",
       "UR         0.000000e+00      UR\n",
       "NW         0.000000e+00      NW\n",
       "OW         0.000000e+00      OW\n",
       "GL         0.000000e+00      GL\n",
       "BL         0.000000e+00      BL\n",
       "AI         0.000000e+00      AI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, computing the sums\n",
    "grant_data['Approved Amount'] = pd.to_numeric(grant_data['Approved Amount'], errors='coerce')\n",
    "grant_canton = grant_data.groupby(grant_data.Canton).sum()\n",
    "grant_canton.loc['UR'] = 0.0\n",
    "grant_canton.loc['NW'] = 0.0\n",
    "grant_canton.loc['OW'] = 0.0\n",
    "grant_canton.loc['GL'] = 0.0\n",
    "grant_canton.loc['BL'] = 0.0\n",
    "grant_canton.loc['AI'] = 0.0\n",
    "grant_canton['cantons'] = grant_canton.index\n",
    "grant_canton.sort_values('Approved Amount', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 905: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1cc345e6c9b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                \u001b[0mlegend_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Grant Amount'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                \u001b[0mthreshold_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m1.7e+05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.6e+07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0e+08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3e+09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4e+09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.69e+09\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                reset=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peco/anaconda/lib/python3.5/site-packages/folium/folium.py\u001b[0m in \u001b[0;36mchoropleth\u001b[0;34m(self, geo_path, geo_str, data_out, data, columns, key_on, threshold_scale, fill_color, fill_opacity, line_color, line_weight, line_opacity, legend_name, topojson, reset)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtopojson\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mgeo_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopoJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopojson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_function\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mgeo_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeoJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peco/anaconda/lib/python3.5/site-packages/folium/features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, object_path, style_function, name, overlay, control)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'read'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peco/anaconda/lib/python3.5/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peco/anaconda/lib/python3.5/encodings/ascii.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 905: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "#Build the folium map of Switzerland with highlighted cantons\n",
    "\n",
    "map = folium.Map(location=[46.8,8],  tiles='Mapbox Bright', zoom_start=8)\n",
    "swiss_topo = r'ch-cantons.topojson.json'\n",
    "\n",
    "map.choropleth(geo_path = swiss_topo, topojson = 'objects.cantons',\n",
    "               data=grant_canton,\n",
    "               columns=['cantons', 'Approved Amount'],\n",
    "               key_on='feature.id',\n",
    "               fill_color='BuPu', fill_opacity=0.7, line_opacity=0.5,\n",
    "               legend_name='Grant Amount',\n",
    "               threshold_scale = [ 1.7e+05, 3.6e+07, 1.0e+08, 1.3e+09, 2.4e+09, 3.69e+09],\n",
    "               reset=True)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "We divide the problem by looking at the cantons\n",
    "[image](https://fr.wikipedia.org/wiki/R%C3%B6stigraben#/media/File:Sprachen_CH_2000_fr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**French speaking Universities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "french_university = grant_data[grant_data.Canton.isin(['GE','JU', 'VD','NE'])]\n",
    "french_university = french_university.copy()\n",
    "french_university['Language']='FR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**German speaking Universities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_university = grant_data[grant_data.Canton.isin(['SZ','SO','AG', 'ZG', 'GR','SG', 'BS', 'LU','ZH', 'LA', 'BE', 'AR', 'TG'])]\n",
    "german_university = german_university.copy()\n",
    "german_university['Language']='DE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Universities \n",
    "\n",
    "#### Where to cut the Rostigraben ?\n",
    "Valais, Fribourg and Bern are the 3 cantons that are cut by the Rostigraben. However, depending on where the university is in the canton, it might be in the french or german speaking part.\n",
    "Let's have a look at each of these university for each canton. We will look for the name of the university on google, and depending on the language spoken in the university's city, we will assign a language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valais \n",
    "In valais, all the univeristy are in the French speaking part, besides :\n",
    "\n",
    "- 'Fernfachhochschule Schweiz (Mitglied SUPSI) - FFHS'\n",
    "- 'Pädagogische Hochschule Wallis - PHVS'\n",
    "\n",
    "which are located in Brig, in the Swiss German part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Centre de rech. sur l'environnement alpin - CREALP\",\n",
       "       'Idiap Research Institute - IDIAP',\n",
       "       'Institut Universitaire Kurt Bösch - IUKB',\n",
       "       'Forschungsinstitut für Opthalmologie - IRO',\n",
       "       'Pädagogische Hochschule Wallis - PHVS',\n",
       "       'Fernfachhochschule Schweiz (Mitglied SUPSI) - FFHS',\n",
       "       'NPO (Biblioth., Museen, Verwalt.) - NPO',\n",
       "       'Weitere Spitäler - ASPIT', 'HES de Suisse occidentale - HES-SO'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = grant_data[grant_data.Canton.isin(['VS'])]\n",
    "a['University'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valais_university = grant_data[grant_data.Canton.isin(['VS'])]\n",
    "valais_university = valais_university.copy()\n",
    "valais_university['Language'] = 'FR'\n",
    "valais_university.loc['Fernfachhochschule Schweiz (Mitglied SUPSI) - FFHS','Language'] = 'DE'\n",
    "valais_university.loc['Pädagogische Hochschule Wallis - PHVS','Language'] = 'DE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fribourg\n",
    "\n",
    "**Assumption** We say that the city of Fribourg is french speaking as 80% of the population speak French\n",
    "\n",
    "\n",
    "In Fribourg, all the univeristy are in the city of Fribourg ( French speaking) , but :\n",
    "\n",
    "- 'Firmen/Privatwirtschaft - FP'\n",
    "\n",
    "which is located in Fribourg, but speaks German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Université de Fribourg - FR',\n",
       "       'Haute école pédagogique fribourgeoise - HEPFR',\n",
       "       'NPO (Biblioth., Museen, Verwalt.) - NPO',\n",
       "       'Firmen/Privatwirtschaft - FP',\n",
       "       'HES de Suisse occidentale - HES-SO', nan], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = grant_data[grant_data.Canton.isin(['FR'])]\n",
    "a['University'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fribourg_university = grant_data[grant_data.Canton.isin(['FR'])]\n",
    "fribourg_university = fribourg_university.copy()\n",
    "fribourg_university['Language'] = 'FR'\n",
    "fribourg_university.loc['Firmen/Privatwirtschaft - FP'] = 'DE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bern\n",
    "\n",
    "**Assumption** We say that the city of Bern is German speaking.\n",
    "\n",
    "\n",
    "In Bern, all the univeristies are in the city of Bern ( German speaking).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Universität Bern - BE', 'Robert Walser-Stiftung Bern - RWS',\n",
       "       'Berner Fachhochschule - BFH',\n",
       "       'Pädagogische Hochschule Bern - PHBern',\n",
       "       'NPO (Biblioth., Museen, Verwalt.) - NPO',\n",
       "       'Firmen/Privatwirtschaft - FP',\n",
       "       'Forschungsanstalten Agroscope - AGS', 'Weitere Institute - FINST',\n",
       "       nan], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = grant_data[grant_data.Canton.isin(['BE'])]\n",
    "a['University'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bern_university = grant_data[grant_data.Canton.isin(['BE'])]\n",
    "bern_university = bern_university.copy()\n",
    "bern_university['Language'] = 'DE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate all the dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_cantons = pd.concat([french_university,german_university,valais_university,fribourg_university,bern_university])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approved Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>8.658452e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>5.272519e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Approved Amount\n",
       "Language                 \n",
       "DE           8.658452e+09\n",
       "FR           5.272519e+09"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, computing the sums\n",
    "language_cantons['Approved Amount'] = pd.to_numeric(language_cantons['Approved Amount'], errors='coerce')\n",
    "language_cantons_ = language_cantons.groupby(language_cantons.Language).sum()\n",
    "language_cantons1 = language_cantons.groupby(language_cantons.Language).count()\n",
    "\n",
    "language_cantons_.sort_values('Approved Amount', ascending = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of university in each part of Rostigraben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          University\n",
       "Language            \n",
       "DE                46\n",
       "FR                29"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=language_cantons[['University','Language']]\n",
    "df=df.drop_duplicates()\n",
    "df.groupby(df.Language).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
